{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140778d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe095f2",
   "metadata": {},
   "source": [
    "# Dealing with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f648d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('bodyfat.csv')\n",
    "data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize header names.\n",
    "def rename_coloumn(data):\n",
    "    #data = data.rename(columns={'Abdomen': 'Waist'})\n",
    "    data.rename(columns={'Abdomen': 'Waist'}, inplace=True)\n",
    "    \n",
    "def coloumn_names_lwr(data):\n",
    "    data.columns = map(str.lower, data.columns)\n",
    "    data.head()\n",
    "    #data.columns = [x.lower() for x in data.columns]\n",
    "    \n",
    "def coloumn_names_captl(data):\n",
    "    data.columns = map(str.capitalize, data.columns)\n",
    "    data.head()\n",
    "    #data.columns = [x.capitalize() for x in data.columns]    \n",
    "'''\n",
    "def replace_whitespaces(data):\n",
    "    cols = []\n",
    "    for col in data.columns:\n",
    "        cols.append(col.replace(' ', '_'))\n",
    "    data.columns = cols\n",
    "    return data\n",
    "'''    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_data(data):\n",
    "    print(f\"zero values in the dataset\\n: {data.isnull().sum() * 100 / len(data)}\")\n",
    "    print(f\"unknown values in the dataset:{data.isna().sum() * 100 / len(data)}\")\n",
    "    print(\"\\n\")\n",
    "    print(\"do you wish to clean your data set ?\")\n",
    "    userinput = input(\"press 1 to clean, press 0 to skip\")\n",
    "    if userinput == 1:\n",
    "        print(\"cleaning your data set ... \")\n",
    "    elif userinput != 0:\n",
    "        print(\"Cleaning skipped..\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a02207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numercial and categorical data\n",
    "\n",
    "numerical_values = pd.DataFrame()\n",
    "continuous_values = pd.DataFrame()\n",
    "categorical_values = pd.DataFrame()\n",
    "\n",
    "def check_datatypes(data):\n",
    "    numerical = data.select_dtypes(np.number)\n",
    "    numerical_continuous = data.select_dtypes(include=['float64'])\n",
    "    categorical = data.select_dtypes(object)\n",
    "    return numerical,numerical_continuous,categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b806ae",
   "metadata": {},
   "source": [
    "Omitting the density coloumn on purpose because to predict the body fat percentage of a person based on the circumferential measurements already available, which is good enough to predict with so much available data.\n",
    "\n",
    "I will, create Model only with these data, and predict again with my personal data set for the information randomly to validate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a82e3d",
   "metadata": {},
   "source": [
    "Fat (%) = [(4*95/density) -4.51 x 100]\n",
    "\n",
    "source:https://www.cambridge.org/core/services/aop-cambridge-core/content/view/DA80501B784742B9B2F4F454BDEE923B/S0007114567000728a.pdf/the-assessment-of-the-amount-of-fat-in-the-human-body-from-measurements-of-skinfold-thickness.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05acbac7",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d170dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dataset to metric system\n",
    "def convert_weight_kg(data):\n",
    "    data['weight']=data['weight'].apply(lambda x : round((x * 0.453),2))\n",
    "    \n",
    "def convert_inch_to_cm(data):\n",
    "    #drop weight, density and body fat percentage\n",
    "    # 12 inches --> 30 cm\n",
    "    #formula X cm = [30/12] * input inches\n",
    "    df_drops = data[['density','bodyfat','age','weight']]\n",
    "    df2 = data.drop(['density','bodyfat','age','weight'], axis=1)\n",
    "    df2 = df2.apply(lambda x : x * 2.5)\n",
    "    data = pd.concat([df_drops, df2], axis=1, join=\"outer\")\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3e335",
   "metadata": {},
   "source": [
    "Finding the Relationships:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9279f4",
   "metadata": {},
   "source": [
    "I am concerned about the correlation between the Label = 'Bodyfat%' and the features = [weight,Chest,abdomen, hip, Bicep,Thigh]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb18409",
   "metadata": {},
   "source": [
    "so I am going to find the Correation between them, by dropping the rest as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_correlation(data):\n",
    "#    df_corr = data.drop(['density','age'], axis=1)\n",
    "#    sns.heatmap(df_corr.corr())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bfaf2",
   "metadata": {},
   "source": [
    "I will try to find the highly correlated value to the label bodyfat and try to fit them:\n",
    "* In our case we can see that the features, weight,chest,abdomen, hip,thigh are all closely correlated.\n",
    "* we will try to find the correlation again by dropping the other fewatures for our consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new coloumn waist to hip ratio\n",
    "def waist_to_hip(data):\n",
    "    data[\"waist_to_hip\"] = data['waist']/data['hip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75024459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalise_correlation(data, cols_to_drop):\n",
    "    df_corr = data.drop(cols_to_drop, axis=1)\n",
    "    sns.heatmap(df_corr.corr(), annot=True)\n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964d11e",
   "metadata": {},
   "source": [
    "NOTE:we witness here that abdomen circumference somewhat highly correlated and is a key contributor to the Bodyfat Percentage. But according to my Domain knowledge, waist(abdomen) to hip ratio is a significant contributor to calculate the bodyfat percentage.\n",
    "so with this in mind I will do some \"Feature Engineering\", with WHR(waist to hip ratio) as another feature in the table.\n",
    "\n",
    "sources:\n",
    "1. https://www.bhf.org.uk/informationsupport/heart-matters-magazine/nutrition/weight/best-way-to-measure-body-fat\n",
    "    \n",
    "2. https://www.medicalnewstoday.com/articles/319439#how-does-waist-to-hip-ratio-affect-health\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cab713",
   "metadata": {},
   "source": [
    "Conclusion: Since the features Bodyfat and Waist asre highly correlated to the WHR, we will construct a linear regression model around Bodyfat and WHR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe25076",
   "metadata": {},
   "source": [
    "# Collinearity, Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f9fa8",
   "metadata": {},
   "source": [
    "Checking the Linear Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find linear Hypotheis using a scatter plot\n",
    "def plot_scatter(X,y):\n",
    "    #figure(figsize=(8, 6), dpi=80)\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "    sns.set()\n",
    "    plt.plot(X_np, y_np, 'o')\n",
    "    m, b = np.polyfit(X_np, y_np, 1)\n",
    "    plt.plot(X_np, m*X_np + b)\n",
    "    #sns.set()\n",
    "    #sns.scatterplot(X,y)\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931396c7",
   "metadata": {},
   "source": [
    "Normalising the Distribution:\n",
    "Since we do not have multiple features to predict the label, we don't use any transformation methods liske standard scalar or Min-Max scalar\n",
    "\n",
    "we go on to create a 1. model after train test split 2.check the error metrics to check the accuracy 3. save the model 4.use external data on this model to predict the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d63a4",
   "metadata": {},
   "source": [
    "Separate the features from the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def separate_label_features(data):\n",
    "#    y = data['TARGET_D']\n",
    "#    X = data.drop(['TARGET_D'], axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726778c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c436727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion calls and declarations\n",
    "numerical_values = pd.DataFrame()\n",
    "continuous_values = pd.DataFrame()\n",
    "categorical_values = pd.DataFrame()\n",
    "cols_to_drop = ['density','age','neck','thigh','height','knee','ankle','forearm','wrist']\n",
    "df_corr = pd.DataFrame()\n",
    "data[\"waist_to_hip\"] = ''\n",
    "rename_coloumn(data)\n",
    "coloumn_names_lwr(data)\n",
    "check_missing_data(data)\n",
    "numerical_values,continuous_values,categorical_values = check_datatypes(data)\n",
    "convert_weight_kg(data)\n",
    "convert_inch_to_cm(numerical_values)\n",
    "#find_correlation(data)#find_correlation(numerical_values)#input numerical values\n",
    "waist_to_hip(data)\n",
    "df_corr = finalise_correlation(data, cols_to_drop)#pick highly correlated feature dataframes to predict the label\n",
    "df_corr\n",
    "\n",
    "#numerical_values.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977f8eb",
   "metadata": {},
   "source": [
    "plot the features distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae50763",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=data,x=\"waist\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=data,x=\"waist_to_hip\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=data,x=\"bodyfat\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96876b0",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(X,y)\n",
    "\n",
    "# Splitting the data\n",
    "#X = data[[\"waist_to_hip\"]] #after confirming the highest correlations fill X and y\n",
    "X = data[[\"waist\"]] #after confirming the highest correlations fill X and y\n",
    "y = data[\"bodyfat\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split( X, y, test_size=0.35, random_state=4)\n",
    "\n",
    "# Split outputs\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(data['waist'],data['bodyfat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b17cd8",
   "metadata": {},
   "source": [
    "Transform the feature(s) before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = StandardScaler()\n",
    "transformer.fit(X)\n",
    "x_standardized = transformer.transform(X)\n",
    "x_standardized_df = pd.DataFrame(x_standardized, columns=X.columns)\n",
    "plot_scatter(x_standardized_df,data['bodyfat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc8e18",
   "metadata": {},
   "source": [
    "Regression on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98943d",
   "metadata": {},
   "source": [
    "Both on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lm.predict(X_train)\n",
    "y_pred_test  = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457f969",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2dde8b",
   "metadata": {},
   "source": [
    "X-y splitting\n",
    "Normalizing (numericals)\n",
    "Concating DataFrames ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
